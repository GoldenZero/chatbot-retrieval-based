{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(word):\n",
    "    with open(\"./question_tokenizer.dict\",'r') as f:\n",
    "        text = f.readlines()\n",
    "    for i in text:\n",
    "        if i.split(\" \")[0] == word:\n",
    "            return (eval((i.split(\" \")[1]).split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ground_Truth</th>\n",
       "      <th>e0</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "      <th>e8</th>\n",
       "      <th>source_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>在 哪里 报名 呢 ？</td>\n",
       "      <td>什么 时候 确认 报名 ？</td>\n",
       "      <td>什么 时候 截止 报名 ？</td>\n",
       "      <td>可以 给 朋友 报名 吗 ？</td>\n",
       "      <td>报名 成功 后 有 什么 通知 吗</td>\n",
       "      <td>活动 售罄 了 还 可以 报名 吗</td>\n",
       "      <td>什么 时候 可以 确定 报名 成功</td>\n",
       "      <td>什么 时候 可以 确定 报名 成功</td>\n",
       "      <td>篱苑 书屋 的 活动 还 可以 报名 吗 ？</td>\n",
       "      <td>为什么 我 不能 报名 了 呢 ， 提示 活动 无法 报名 ？</td>\n",
       "      <td>去 哪 报名 ？</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>篱苑 书屋 的 活动 还 可以 报名 吗 ？</td>\n",
       "      <td>为什么 我 不能 报名 了 呢 ， 提示 活动 无法 报名 ？</td>\n",
       "      <td>什么 时候 确认 报名 ？</td>\n",
       "      <td>什么 时候 截止 报名 ？</td>\n",
       "      <td>可以 给 朋友 报名 吗 ？</td>\n",
       "      <td>在 哪里 报名 呢 ？</td>\n",
       "      <td>报名 成功 后 有 什么 通知 吗</td>\n",
       "      <td>报名 成功 后 有 什么 通知 吗</td>\n",
       "      <td>活动 售罄 了 还 可以 报名 吗</td>\n",
       "      <td>什么 时候 可以 确定 报名 成功</td>\n",
       "      <td>篱苑 还 能 报名 吗</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Ground_Truth                               e0             e1  \\\n",
       "0             在 哪里 报名 呢 ？                    什么 时候 确认 报名 ？  什么 时候 截止 报名 ？   \n",
       "1  篱苑 书屋 的 活动 还 可以 报名 吗 ？  为什么 我 不能 报名 了 呢 ， 提示 活动 无法 报名 ？  什么 时候 确认 报名 ？   \n",
       "\n",
       "               e2                 e3                 e4                 e5  \\\n",
       "0  可以 给 朋友 报名 吗 ？  报名 成功 后 有 什么 通知 吗  活动 售罄 了 还 可以 报名 吗  什么 时候 可以 确定 报名 成功   \n",
       "1   什么 时候 截止 报名 ？     可以 给 朋友 报名 吗 ？        在 哪里 报名 呢 ？  报名 成功 后 有 什么 通知 吗   \n",
       "\n",
       "                  e6                      e7                               e8  \\\n",
       "0  什么 时候 可以 确定 报名 成功  篱苑 书屋 的 活动 还 可以 报名 吗 ？  为什么 我 不能 报名 了 呢 ， 提示 活动 无法 报名 ？   \n",
       "1  报名 成功 后 有 什么 通知 吗       活动 售罄 了 还 可以 报名 吗                什么 时候 可以 确定 报名 成功   \n",
       "\n",
       "  source_question  \n",
       "0        去 哪 报名 ？  \n",
       "1     篱苑 还 能 报名 吗  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('true_env_test_cut.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground_Truth\n",
      "e0\n",
      "e1\n",
      "e2\n",
      "e3\n",
      "e4\n",
      "e5\n",
      "e6\n",
      "e7\n",
      "e8\n",
      "source_question\n",
      "{'e3': [[2445, 947, 72, 5, 2, 2991, 8], [26, 79, 289, 2445, 8, 4]], 'Ground_Truth': [[12, 63, 2445, 59, 4], [82645, 1, 816, 105, 26, 2445, 8, 4]], 'source_question': [[64, 55, 2445, 4], [105, 44, 2445, 8]], 'e2': [[26, 79, 289, 2445, 8, 4], [2, 92, 12874, 2445, 4]], 'e8': [[13, 14, 127, 2445, 11, 59, 9, 1761, 816, 1111, 2445, 4], [2, 92, 26, 1037, 2445, 947]], 'e1': [[2, 92, 12874, 2445, 4], [2, 92, 4202, 2445, 4]], 'e6': [[2, 92, 26, 1037, 2445, 947], [2445, 947, 72, 5, 2, 2991, 8]], 'e0': [[2, 92, 4202, 2445, 4], [13, 14, 127, 2445, 11, 59, 9, 1761, 816, 1111, 2445, 4]], 'e4': [[816, 66995, 11, 105, 26, 2445, 8], [12, 63, 2445, 59, 4]], 'e7': [[82645, 1, 816, 105, 26, 2445, 8, 4], [816, 66995, 11, 105, 26, 2445, 8]], 'e5': [[2, 92, 26, 1037, 2445, 947], [2445, 947, 72, 5, 2, 2991, 8]]}\n"
     ]
    }
   ],
   "source": [
    "dic = {}\n",
    "for key in df.columns.values:\n",
    "    dic[key]=[]\n",
    "    print(key)\n",
    "    for i in range(len(df)):\n",
    "        wordlist = []\n",
    "        for word in df[key][i].split(\" \"):\n",
    "            if lookup(word) != None:\n",
    "                wordlist.append(lookup(word))\n",
    "        dic[key].append(wordlist)\n",
    "print(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ground_Truth': [[12, 63, 2445, 59, 4, 0, 0, 0, 0, 0],\n",
       "  [82645, 1, 816, 105, 26, 2445, 8, 4, 0, 0]],\n",
       " 'e0': [[2, 92, 4202, 2445, 4, 0, 0, 0, 0, 0],\n",
       "  [13, 14, 127, 2445, 11, 59, 9, 1761, 816, 1111]],\n",
       " 'e1': [[2, 92, 12874, 2445, 4, 0, 0, 0, 0, 0],\n",
       "  [2, 92, 4202, 2445, 4, 0, 0, 0, 0, 0]],\n",
       " 'e2': [[26, 79, 289, 2445, 8, 4, 0, 0, 0, 0],\n",
       "  [2, 92, 12874, 2445, 4, 0, 0, 0, 0, 0]],\n",
       " 'e3': [[2445, 947, 72, 5, 2, 2991, 8, 0, 0, 0],\n",
       "  [26, 79, 289, 2445, 8, 4, 0, 0, 0, 0]],\n",
       " 'e4': [[816, 66995, 11, 105, 26, 2445, 8, 0, 0, 0],\n",
       "  [12, 63, 2445, 59, 4, 0, 0, 0, 0, 0]],\n",
       " 'e5': [[2, 92, 26, 1037, 2445, 947, 0, 0, 0, 0],\n",
       "  [2445, 947, 72, 5, 2, 2991, 8, 0, 0, 0]],\n",
       " 'e6': [[2, 92, 26, 1037, 2445, 947, 0, 0, 0, 0],\n",
       "  [2445, 947, 72, 5, 2, 2991, 8, 0, 0, 0]],\n",
       " 'e7': [[82645, 1, 816, 105, 26, 2445, 8, 4, 0, 0],\n",
       "  [816, 66995, 11, 105, 26, 2445, 8, 0, 0, 0]],\n",
       " 'e8': [[13, 14, 127, 2445, 11, 59, 9, 1761, 816, 1111],\n",
       "  [2, 92, 26, 1037, 2445, 947, 0, 0, 0, 0]],\n",
       " 'source_question': [[64, 55, 2445, 4, 0, 0, 0, 0, 0, 0],\n",
       "  [105, 44, 2445, 8, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padding(listl,num):\n",
    "    if len(listl)<num+1:\n",
    "        for i in range(num - len(listl)):\n",
    "            listl.append(0)\n",
    "        listl = np.array(listl).reshape(1,10)\n",
    "    else:\n",
    "        for i in range(len(listl)-num):\n",
    "            listl.pop()\n",
    "        listl = np.array(listl).reshape(1,10)\n",
    "    return listl\n",
    "\n",
    "for i in dic:\n",
    "    for j in dic[i]: \n",
    "        j = padding(j,10)\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Bidirectional\n",
    "from keras.layers import Embedding, LSTM, Input\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.layers import merge\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "def test_model(s,g):\n",
    "    weight_path = 'zhidao_8_15_saved_wt.h5'\n",
    "#     K.clear_session()\n",
    "#     test_xc_textline = test_reader()\n",
    "#     test_xr_textline = test_reader()\n",
    "#     test_xc_textline.init_reader(K.get_session())\n",
    "#     test_xr_textline.init_reader(K.get_session())\n",
    "#     K.get_session().run(test_xc_textline.epoch_input().initializer)\n",
    "#     K.get_session().run(test_xr_textline.epoch_input().initializer)\n",
    "#     test_c = test_xc_textline.epoch_input().get_next()['source_question']\n",
    "#     test_r = test_xr_textline.epoch_input().get_next()[key]\n",
    "    \n",
    "    \n",
    "    test_encoder = Sequential()\n",
    "    embeddin_layer = Embedding(output_dim=100,\n",
    "                        input_dim=530935+1,\n",
    "#                            input_dim = 64906,\n",
    "                        input_length=10,\n",
    "                        mask_zero=True,\n",
    "                        trainable=True)\n",
    "    lstm_layer = LSTM(units=50)\n",
    "    test_encoder.add(embeddin_layer)\n",
    "    test_encoder.add(lstm_layer)\n",
    "\n",
    "    test_context_input = Input(shape=(10,))\n",
    "    test_response_input = Input(shape=(10,))\n",
    "    # context_input = Input(shape=(160,), dtype='float32')\n",
    "    # response_input = Input(shape=(160,), dtype='float32')\n",
    "\n",
    "    test_context_branch = test_encoder(test_context_input)\n",
    "    test_response_branch = test_encoder(test_response_input)\n",
    "\n",
    "    test_concatenated = keras.layers.Dot(axes=1)(\n",
    "                                [test_context_branch, \n",
    "                                 test_response_branch])\n",
    "    test_out = Dense((1), activation = \"sigmoid\") (test_concatenated)\n",
    "    test_dual_encoder = Model([test_context_input, test_response_input], test_out)\n",
    "    test_dual_encoder.load_weights(weight_path)\n",
    "    test_dual_encoder.compile(loss='binary_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "#     test_dual_encoder.summary()\n",
    "\n",
    "    his = test_dual_encoder.predict(x=[s,g],steps=1)\n",
    "    return his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keylist = ['Ground_Truth','e0','e1','e2','e3','e4',\n",
    "           'e5','e6','e7','e8']\n",
    "\n",
    "res = []\n",
    "for i in range(2):\n",
    "    lappend =[]\n",
    "    for key in keylist:\n",
    "        a = test_model(dic['source_question'],dic[key])\n",
    "        lappend.append(a)\n",
    "    res.append(lappend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9804314],\n",
       "       [0.9804314]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(np.array([source_input,source_input]).reshape(2,10),\n",
    "           np.array([target_input,target_input]).reshape(2,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55678046 0.542959   0.5112091  0.46986306 0.22140543 0.52256536\n",
      " 0.33431402 0.33431402 0.413214   0.64163375]\n",
      "[0.9081577  0.64769113 0.4877927  0.56415075 0.8183041  0.90746284\n",
      " 0.5796417  0.5796417  0.8954514  0.22853309]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(res)[0][:,0].reshape(1,10)[0])\n",
    "print(np.array(res)[0][:,1].reshape(1,10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3735685348510742\n",
      "3.1496245861053467\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>source_question</th>\n",
       "      <th>target_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ? 如 : 尐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>像 尐 这样 的 字 还有 哪些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>“ 儿 ” 字 有 哪些 写法 。 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ? 如 : 尐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 , 但 不是 少 , 怎么 打 啊 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>小字 的 笔顺 笔画 顺序</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>一元 钱 的 一字 大写 怎么 写</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐</td>\n",
       "      <td>关于 汉字 的 歇后语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 , 但 不是 少 , 怎么 打 啊 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>上面 一个 小字 . 下面 一个 少字 怎么 打 出来 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>少字 下面 一撇 向 右 怎么弄</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>小字 下面 加 一撇 不 做 少字 猜 请问 是 什么 字</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>\" 小 \" 字 为首 的 歇后语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>哪些 的 成语 里 有 “ 小 ” 字 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>“ 小 ” 字 的 笔画 顺序 是 什么 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>“ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？</td>\n",
       "      <td>小字 结尾 的 成语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>带 小字 四个 字 的 成语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>四个 字 的 成语 有 哪些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>带 大小 的 四字 成语 是 什么</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>可爱 有 什么 四个 字 的 成语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>形容 小 的 四字 成语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>小字 的 笔顺 笔画 顺序</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>带 小 了 字 的 成语 有 哪些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>四个 字 的 成语 带 \" 小 \" 字 的 有 哪些</td>\n",
       "      <td>“ 说 ” 字 第二笔 的 笔画 名称 叫 什么 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>关于 \" 小 \" 字 的 成语</td>\n",
       "      <td>形容 小 的 四字 成语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>关于 \" 小 \" 字 的 成语</td>\n",
       "      <td>哪些 的 成语 里 有 “ 小 ” 字 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>关于 \" 小 \" 字 的 成语</td>\n",
       "      <td>有关 小字 的 成语 有 哪些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>关于 \" 小 \" 字 的 成语</td>\n",
       "      <td>小字 结尾 的 成语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>关于 \" 小 \" 字 的 成语</td>\n",
       "      <td>\" 小 \" 字 为首 的 歇后语</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>关于 \" 小 \" 字 的 成语</td>\n",
       "      <td>大写 的 小 怎么 写</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7954</th>\n",
       "      <td>1</td>\n",
       "      <td>春天 来 了 是 什么 动作</td>\n",
       "      <td>性爱 中 春天 来 了 是 什么 姿势</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>1</td>\n",
       "      <td>春天 来 了 是 什么 动作</td>\n",
       "      <td>给 儿歌 春天 来 了 加 动作</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>0</td>\n",
       "      <td>春天 来 了 是 什么 动作</td>\n",
       "      <td>侧耳 听春步 ;   求赐 下联 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>0</td>\n",
       "      <td>春天 来 了 是 什么 动作</td>\n",
       "      <td>朱自清 《 春 》 赏析 ? 各段 赏析</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>0</td>\n",
       "      <td>春天 来 了 是 什么 动作</td>\n",
       "      <td>用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7959</th>\n",
       "      <td>0</td>\n",
       "      <td>春天 来 了 是 什么 动作</td>\n",
       "      <td>《 春 》 朱自清 全文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7960</th>\n",
       "      <td>1</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>朱自清 《 春 》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7961</th>\n",
       "      <td>1</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7962</th>\n",
       "      <td>1</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>朱自清   春</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7963</th>\n",
       "      <td>1</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>《 春 》 朱自清</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7964</th>\n",
       "      <td>0</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>朱自清 的 《 春 》 原文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7965</th>\n",
       "      <td>0</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>春天 来 了 , 鸟儿 都 有 什么 动作 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7966</th>\n",
       "      <td>0</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>朱自清 — — 《 春 》 完整 的 全文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7967</th>\n",
       "      <td>0</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "      <td>朱自清 &amp; lt ; &amp; lt ; 春 &amp; gt ; &amp; gt ; 原文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>\" 夜船 归草市 , 春步 上 茶山 \" 是 什么 意思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7969</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>我经 朋友 介绍 依江春 , 不 知道 是 传销 , 还是 真的 能 像 她们 说 的 一样...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>亲微 商是 骗人 的 吗 ? 那 依江春 也 是 骗人 的 吗 ? 谢谢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>\" 夜船 归草市 , 春步 上 茶山 \" 是 什么 意思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>朱自清 巜 春 》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>朱自清 《 春 》 原文</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>《 春 》 朱自清</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>\" 夜船 归草市 , 春步 上 茶山 \" 是 什么 意思</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7977</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>我经 朋友 介绍 依江春 , 不 知道 是 传销 , 还是 真的 能 像 她们 说 的 一样...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>1</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>亲微 商是 骗人 的 吗 ? 那 依江春 也 是 骗人 的 吗 ? 谢谢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>侧耳 听春步 ;   求赐 下联 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>初一 语文 《 春 》</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>0</td>\n",
       "      <td>\" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思</td>\n",
       "      <td>春   朱自清   原文</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                      source_question  \\\n",
       "0         1         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "1         1         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "2         1         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "3         1         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "4         0         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "5         0         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "6         0         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "7         0         “ 小 ” 字 的 多种 写法 有 哪些 ？ 如 ： 尐   \n",
       "8         1  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "9         1  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "10        1  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "11        1  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "12        0  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "13        0  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "14        0  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "15        0  “ 小 ” 字 下面 有 一撇 ， 但 不是 少 ， 怎么 打 啊 ？   \n",
       "16        1           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "17        1           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "18        1           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "19        1           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "20        0           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "21        0           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "22        0           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "23        0           四个 字 的 成语 带 \" 小 \" 字 的 有 哪些   \n",
       "24        1                      关于 \" 小 \" 字 的 成语   \n",
       "25        1                      关于 \" 小 \" 字 的 成语   \n",
       "26        1                      关于 \" 小 \" 字 的 成语   \n",
       "27        1                      关于 \" 小 \" 字 的 成语   \n",
       "28        0                      关于 \" 小 \" 字 的 成语   \n",
       "29        0                      关于 \" 小 \" 字 的 成语   \n",
       "...     ...                                  ...   \n",
       "7954      1                       春天 来 了 是 什么 动作   \n",
       "7955      1                       春天 来 了 是 什么 动作   \n",
       "7956      0                       春天 来 了 是 什么 动作   \n",
       "7957      0                       春天 来 了 是 什么 动作   \n",
       "7958      0                       春天 来 了 是 什么 动作   \n",
       "7959      0                       春天 来 了 是 什么 动作   \n",
       "7960      1                            朱自清 巜 春 》   \n",
       "7961      1                            朱自清 巜 春 》   \n",
       "7962      1                            朱自清 巜 春 》   \n",
       "7963      1                            朱自清 巜 春 》   \n",
       "7964      0                            朱自清 巜 春 》   \n",
       "7965      0                            朱自清 巜 春 》   \n",
       "7966      0                            朱自清 巜 春 》   \n",
       "7967      0                            朱自清 巜 春 》   \n",
       "7968      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7969      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7970      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7971      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7972      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7973      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7974      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7975      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7976      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7977      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7978      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7979      1         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7980      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7981      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7982      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "7983      0         \" 夜船 归草市 ， 春步 上 茶山 \" 是 什么 意思   \n",
       "\n",
       "                                        target_question  \n",
       "0                          “ 小 ” 字 的 多种 写法 有 哪些 ? 如 : 尐  \n",
       "1                                      像 尐 这样 的 字 还有 哪些  \n",
       "2                                   “ 儿 ” 字 有 哪些 写法 。 ?  \n",
       "3                          “ 小 ” 字 的 多种 写法 有 哪些 ? 如 : 尐  \n",
       "4                   “ 小 ” 字 下面 有 一撇 , 但 不是 少 , 怎么 打 啊 ?  \n",
       "5                                         小字 的 笔顺 笔画 顺序  \n",
       "6                                     一元 钱 的 一字 大写 怎么 写  \n",
       "7                                           关于 汉字 的 歇后语  \n",
       "8                   “ 小 ” 字 下面 有 一撇 , 但 不是 少 , 怎么 打 啊 ?  \n",
       "9                         上面 一个 小字 . 下面 一个 少字 怎么 打 出来 ?  \n",
       "10                                     少字 下面 一撇 向 右 怎么弄  \n",
       "11                        小字 下面 加 一撇 不 做 少字 猜 请问 是 什么 字  \n",
       "12                                     \" 小 \" 字 为首 的 歇后语  \n",
       "13                                哪些 的 成语 里 有 “ 小 ” 字 ?  \n",
       "14                               “ 小 ” 字 的 笔画 顺序 是 什么 ?  \n",
       "15                                           小字 结尾 的 成语  \n",
       "16                                       带 小字 四个 字 的 成语  \n",
       "17                                       四个 字 的 成语 有 哪些  \n",
       "18                                    带 大小 的 四字 成语 是 什么  \n",
       "19                                    可爱 有 什么 四个 字 的 成语  \n",
       "20                                         形容 小 的 四字 成语  \n",
       "21                                        小字 的 笔顺 笔画 顺序  \n",
       "22                                    带 小 了 字 的 成语 有 哪些  \n",
       "23                           “ 说 ” 字 第二笔 的 笔画 名称 叫 什么 ?  \n",
       "24                                         形容 小 的 四字 成语  \n",
       "25                                哪些 的 成语 里 有 “ 小 ” 字 ?  \n",
       "26                                      有关 小字 的 成语 有 哪些  \n",
       "27                                           小字 结尾 的 成语  \n",
       "28                                     \" 小 \" 字 为首 的 歇后语  \n",
       "29                                          大写 的 小 怎么 写  \n",
       "...                                                 ...  \n",
       "7954                                性爱 中 春天 来 了 是 什么 姿势  \n",
       "7955                                   给 儿歌 春天 来 了 加 动作  \n",
       "7956                                 侧耳 听春步 ;   求赐 下联 !  \n",
       "7957                               朱自清 《 春 》 赏析 ? 各段 赏析  \n",
       "7958            用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么  \n",
       "7959                                       《 春 》 朱自清 全文  \n",
       "7960                                          朱自清 《 春 》  \n",
       "7961                                          朱自清 巜 春 》  \n",
       "7962                                            朱自清   春  \n",
       "7963                                          《 春 》 朱自清  \n",
       "7964                                     朱自清 的 《 春 》 原文  \n",
       "7965                            春天 来 了 , 鸟儿 都 有 什么 动作 ?  \n",
       "7966                              朱自清 — — 《 春 》 完整 的 全文  \n",
       "7967               朱自清 & lt ; & lt ; 春 & gt ; & gt ; 原文  \n",
       "7968                       \" 夜船 归草市 , 春步 上 茶山 \" 是 什么 意思  \n",
       "7969  我经 朋友 介绍 依江春 , 不 知道 是 传销 , 还是 真的 能 像 她们 说 的 一样...  \n",
       "7970            用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么  \n",
       "7971               亲微 商是 骗人 的 吗 ? 那 依江春 也 是 骗人 的 吗 ? 谢谢  \n",
       "7972                       \" 夜船 归草市 , 春步 上 茶山 \" 是 什么 意思  \n",
       "7973                                          朱自清 巜 春 》  \n",
       "7974                                       朱自清 《 春 》 原文  \n",
       "7975                                          《 春 》 朱自清  \n",
       "7976                       \" 夜船 归草市 , 春步 上 茶山 \" 是 什么 意思  \n",
       "7977  我经 朋友 介绍 依江春 , 不 知道 是 传销 , 还是 真的 能 像 她们 说 的 一样...  \n",
       "7978            用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么  \n",
       "7979               亲微 商是 骗人 的 吗 ? 那 依江春 也 是 骗人 的 吗 ? 谢谢  \n",
       "7980                                 侧耳 听春步 ;   求赐 下联 !  \n",
       "7981                                        初一 语文 《 春 》  \n",
       "7982            用 了 依江春 之后 冲洗 出 一些 像 死 皮 一样 的 弄 东西 是 什么  \n",
       "7983                                       春   朱自清   原文  \n",
       "\n",
       "[7984 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 11.5030 - acc: 0.1146 - val_loss: 11.1807 - val_acc: 0.1354\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.5106 - acc: 0.1167 - val_loss: 10.7033 - val_acc: 0.0833\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4740 - acc: 0.1292 - val_loss: 10.7855 - val_acc: 0.0625\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.5000 - acc: 0.1375 - val_loss: 11.0543 - val_acc: 0.0938\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5025 - acc: 0.1562 - val_loss: 11.1705 - val_acc: 0.1354\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5023 - acc: 0.1635 - val_loss: 10.7034 - val_acc: 0.0938\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4816 - acc: 0.1688 - val_loss: 10.7862 - val_acc: 0.0729\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4705 - acc: 0.1792 - val_loss: 11.0537 - val_acc: 0.0729\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4512 - acc: 0.1802 - val_loss: 11.1736 - val_acc: 0.0938\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4555 - acc: 0.1823 - val_loss: 10.7013 - val_acc: 0.0833\n",
      "30/30 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.414953009287517, 0.175]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "model = keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)\n",
    "\n",
    "except:\n",
    "    print(\"error\")\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "      validation_data=val_dataset,\n",
    "      validation_steps=3)\n",
    "model.evaluate(dataset, steps=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# embeddings_index = {}\n",
    "# embedding_file = \"/mnt/cephfs/ktqueue/jobs/tf-lattice-lm-sum-weight-char-less-tempdecay-0524-0/code/save/embedding_last\"\n",
    "# with open(embedding_file, 'r') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         try:\n",
    "#             coefs = np.asarray(values[1:], dtype='float32')\n",
    "#         except ValueError:\n",
    "#             continue\n",
    "#         embeddings_index[word] = coefs\n",
    "\n",
    "# word_dict = {}\n",
    "# dict_file_path = \"./question_tokenizer.dict\"      \n",
    "# with open(dict_file_path, 'r') as f:\n",
    "#     for l in f.readlines():\n",
    "#         word, idx = l.split(' ')[0], l.split(' ')[1]\n",
    "#         word_dict[word] = int(idx)\n",
    "# print(\"word_dict size:\", len(word_dict))\n",
    "\n",
    "# MAX_NB_WORDS = len(embeddings_index)\n",
    "# num_words = min(MAX_NB_WORDS, len(word_dict)) + 1\n",
    "# embedding_matrix = np.zeros((num_words , 256))\n",
    "\n",
    "# for word, i in word_dict.items():\n",
    "#     if i >= MAX_NB_WORDS:\n",
    "#         continue\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         # words not found in embedding index will be all-zeros.\n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "import pickle\n",
    "# output = open('embedding_vector.pkl', 'wb')\n",
    "# pickle.dump(embedding_matrix, output)\n",
    "pkl_file = open('embedding_vector.pkl', 'rb')\n",
    "embedding_matrix = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from models import helpers\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "def get_embeddings(hparams):\n",
    "    if hparams.glove_path and hparams.vocab_path:\n",
    "        tf.logging.info(\"Loading Glove embeddings...\")\n",
    "        vocab_array, vocab_dict = helpers.load_vocab(hparams.vocab_path)\n",
    "        glove_vectors, glove_dict = helpers.load_glove_vectors(\n",
    "            hparams.glove_path, vocab=set(vocab_array))\n",
    "        initializer = helpers.build_initial_embedding_matrix(vocab_dict, \n",
    "            glove_dict, glove_vectors, hparams.embedding_dim)\n",
    "    else:\n",
    "        tf.logging.info(\"No glove/vocab path specificed, starting with random embeddings.\")\n",
    "        initializer = tf.random_uniform_initializer(-0.25, 0.25)\n",
    "\n",
    "    return tf.get_variable(\n",
    "        \"word_embeddings\",\n",
    "        shape=[hparams.vocab_size, hparams.embedding_dim],\n",
    "        initializer=initializer)\n",
    "\n",
    "\n",
    "def dual_encoder_model(\n",
    "    hparams,\n",
    "    mode,\n",
    "    context,\n",
    "    context_len,\n",
    "    utterance,\n",
    "    utterance_len,\n",
    "    targets):\n",
    "\n",
    "  # Initialize embedidngs randomly or with pre-trained vectors if available\n",
    "    embeddings_W = get_embeddings(hparams)\n",
    "\n",
    "  # Embed the context and the utterance\n",
    "    context_embedded = tf.nn.embedding_lookup(\n",
    "      embeddings_W, context, name=\"embed_context\")\n",
    "    utterance_embedded = tf.nn.embedding_lookup(\n",
    "      embeddings_W, utterance, name=\"embed_utterance\")\n",
    "\n",
    "\n",
    "  # Build the RNN\n",
    "    with tf.variable_scope(\"rnn\") as vs:\n",
    "    # We use an LSTM Cell\n",
    "        cell = tf.nn.rnn_cell.LSTMCell(\n",
    "            hparams.rnn_dim,\n",
    "            forget_bias=2.0,\n",
    "            use_peepholes=True,\n",
    "            state_is_tuple=True)\n",
    "\n",
    "        # Run the utterance and context through the RNN\n",
    "        rnn_outputs, rnn_states = tf.nn.dynamic_rnn(\n",
    "            cell,\n",
    "            tf.concat(0, [context_embedded, utterance_embedded]),\n",
    "            sequence_length=tf.concat(0, [context_len, utterance_len]),\n",
    "            dtype=tf.float32)\n",
    "        encoding_context, encoding_utterance = tf.split(0, 2, rnn_states.h)\n",
    "\n",
    "    with tf.variable_scope(\"prediction\") as vs:\n",
    "        M = tf.get_variable(\"M\",\n",
    "          shape=[hparams.rnn_dim, hparams.rnn_dim],\n",
    "          initializer=tf.truncated_normal_initializer())\n",
    "\n",
    "        # \"Predict\" a  response: c * M\n",
    "        generated_response = tf.matmul(encoding_context, M)\n",
    "        generated_response = tf.expand_dims(generated_response, 2)\n",
    "        encoding_utterance = tf.expand_dims(encoding_utterance, 2)\n",
    "\n",
    "        # Dot product between generated response and actual response\n",
    "        # (c * M) * r\n",
    "        logits = tf.batch_matmul(generated_response, encoding_utterance, True)\n",
    "        logits = tf.squeeze(logits, [2])\n",
    "\n",
    "        # Apply sigmoid to convert logits to probabilities\n",
    "        probs = tf.sigmoid(logits)\n",
    "\n",
    "        if mode == tf.contrib.learn.ModeKeys.INFER:\n",
    "            return probs, None\n",
    "\n",
    "        # Calculate the binary cross-entropy loss\n",
    "        losses = tf.nn.sigmoid_cross_entropy_with_logits(logits, tf.to_float(targets))\n",
    "\n",
    "  # Mean loss across the batch of examples\n",
    "    mean_loss = tf.reduce_mean(losses, name=\"mean_loss\")\n",
    "    return probs, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import udc_model\n",
    "import udc_hparams\n",
    "import udc_metrics\n",
    "import udc_inputs\n",
    "from models.dual_encoder import dual_encoder_model\n",
    "\n",
    "tf.flags.DEFINE_string(\"input_dir\", \"./data\", \"Directory containing input data files 'train.tfrecords' and 'validation.tfrecords'\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", None, \"Directory to store model checkpoints (defaults to ./runs)\")\n",
    "tf.flags.DEFINE_integer(\"loglevel\", 20, \"Tensorflow log level\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", None, \"Number of training Epochs. Defaults to indefinite.\")\n",
    "tf.flags.DEFINE_integer(\"eval_every\", 2000, \"Evaluate after this many train steps\")\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "TIMESTAMP = int(time.time())\n",
    "\n",
    "if FLAGS.model_dir:\n",
    "    MODEL_DIR = FLAGS.model_dir\n",
    "else:\n",
    "    MODEL_DIR = os.path.abspath(os.path.join(\"./runs\", str(TIMESTAMP)))\n",
    "\n",
    "TRAIN_FILE = os.path.abspath(os.path.join(FLAGS.input_dir, \"train.tfrecords\"))\n",
    "VALIDATION_FILE = os.path.abspath(\n",
    "    os.path.join(FLAGS.input_dir, \"validation.tfrecords\"))\n",
    "\n",
    "tf.logging.set_verbosity(FLAGS.loglevel)\n",
    "\n",
    "def main(unused_argv):\n",
    "    hparams = udc_hparams.create_hparams()\n",
    "\n",
    "    model_fn = udc_model.create_model_fn(hparams,\n",
    "                model_impl=dual_encoder_model)\n",
    "\n",
    "    estimator = tf.contrib.learn.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir=MODEL_DIR,\n",
    "    config=tf.contrib.learn.RunConfig())\n",
    "\n",
    "    input_fn_train = udc_inputs.create_input_fn(\n",
    "    mode=tf.contrib.learn.ModeKeys.TRAIN,\n",
    "    input_files=[TRAIN_FILE],\n",
    "    batch_size=hparams.batch_size,\n",
    "    num_epochs=FLAGS.num_epochs)\n",
    "\n",
    "    input_fn_eval = udc_inputs.create_input_fn(\n",
    "    mode=tf.contrib.learn.ModeKeys.EVAL,\n",
    "    input_files=[VALIDATION_FILE],\n",
    "    batch_size=hparams.eval_batch_size,\n",
    "    num_epochs=1)\n",
    "\n",
    "    eval_metrics = udc_metrics.create_evaluation_metrics()\n",
    "\n",
    "    eval_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        input_fn=input_fn_eval,\n",
    "        every_n_steps=FLAGS.eval_every,\n",
    "        metrics=eval_metrics)\n",
    "\n",
    "    estimator.fit(input_fn=input_fn_train, steps=None, monitors=[eval_monitor])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
